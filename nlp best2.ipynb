{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9e682b-c44d-44d2-89dc-caa17c7bb1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open ('C:/Users/ADMIN/Documents/mob.txt','r', encoding = 'utf-8') as file:\n",
    "    bk = file.read()\n",
    "\n",
    "sentences= sent_tokenize(bk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8716c36-d19a-4847-bb2e-12d04c82bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"spacytextblob\")\n",
    "il = []\n",
    "for s in sentences:\n",
    "    doc = nlp(s)\n",
    "    p = doc._.polarity\n",
    "    if p > 0:\n",
    "        il.append(1)\n",
    "    else:\n",
    "        il.append(0)\n",
    "\n",
    "labels = np.array(il)\n",
    "        \n",
    "\n",
    "t = Tokenizer(num_words = 10000, oov_token = \"<OOV>\")\n",
    "t.fit_on_texts(sentences)\n",
    "sequence = t.texts_to_sequences(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c399e6-36fb-48f5-b682-056dabfbc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "ml = max([len(seq) for seq in sequence])\n",
    "ps = pad_sequences(sequence, maxlen = ml, padding = 'post')\n",
    "X_train,X_test,y_train,y_test = train_test_split(ps,labels, test_size = 0.3, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c9b67d-cc66-40ec-94e7-036909b68b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 56, 128)           48768     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 56, 80)           54080     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 80)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 40)                3240      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106,129\n",
      "Trainable params: 106,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,GlobalMaxPooling1D,Bidirectional,Dropout\n",
    "\n",
    "vs = len(t.word_index) + 1\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim = vs, output_dim = 128, input_length = ml),\n",
    "    Bidirectional(LSTM(40, return_sequences = True)),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(units = 40, activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units = 1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee14e48-dab9-4219-99c3-048400f29891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "25/25 - 34s - loss: 0.7009 - accuracy: 0.4000 - val_loss: 0.6944 - val_accuracy: 0.4545 - 34s/epoch - 1s/step\n",
      "Epoch 2/7\n",
      "25/25 - 1s - loss: 0.6810 - accuracy: 0.6000 - val_loss: 0.6909 - val_accuracy: 0.5455 - 1s/epoch - 41ms/step\n",
      "Epoch 3/7\n",
      "25/25 - 1s - loss: 0.6455 - accuracy: 0.6400 - val_loss: 0.6923 - val_accuracy: 0.5455 - 1s/epoch - 42ms/step\n",
      "Epoch 4/7\n",
      "25/25 - 1s - loss: 0.5703 - accuracy: 0.8400 - val_loss: 0.7005 - val_accuracy: 0.5455 - 1s/epoch - 40ms/step\n",
      "Epoch 5/7\n",
      "25/25 - 1s - loss: 0.2627 - accuracy: 1.0000 - val_loss: 0.8585 - val_accuracy: 0.7273 - 945ms/epoch - 38ms/step\n",
      "Epoch 6/7\n",
      "25/25 - 1s - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.2616 - val_accuracy: 0.7273 - 967ms/epoch - 39ms/step\n",
      "Epoch 7/7\n",
      "25/25 - 1s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.9846 - val_accuracy: 0.8182 - 962ms/epoch - 38ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "h = model.fit(X_train,y_train, epochs = 7, batch_size = 1, validation_data = (X_test,y_test), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b49916be-3f5a-4cf1-9f2b-18e98330f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(model,nt,t,max_len):\n",
    "    sequences = t.texts_to_sequences([nt])\n",
    "    padseq = pad_sequences(sequences, maxlen=ml, padding = \"post\")\n",
    "    prediction = model.predict(padseq)\n",
    "    return \"Positive\" if prediction  > 0.5 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed25a42e-7c3d-4e29-880a-81656c04b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nt = \"shoot the Commie bastard\"\n",
    "\n",
    "\n",
    "\n",
    "sent = preproc(model,nt,t,ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73b7b8f-2132-4360-9784-6f19b13d9e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d2bb56-ef2f-46ca-b12b-71529f3301f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy310",
   "language": "python",
   "name": "mypy310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
